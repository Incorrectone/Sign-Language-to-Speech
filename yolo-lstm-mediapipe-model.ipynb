{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6677809,"sourceType":"datasetVersion","datasetId":3852662},{"sourceId":12320675,"sourceType":"datasetVersion","datasetId":7766108}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics\nfrom ultralytics import YOLO","metadata":{"_uuid":"e8e674f0-7cbf-47b4-ab26-5e19ec13cf02","_cell_guid":"dc64bd13-b20d-4b55-abd0-df89689432a7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-29T07:40:41.311451Z","iopub.execute_input":"2025-06-29T07:40:41.311775Z","execution_failed":"2025-06-29T07:42:39.020Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install mediapipe","metadata":{"_uuid":"50a89abe-6991-49de-80fa-cef34b5563b1","_cell_guid":"fc3723a4-3498-4a81-b9a5-2c10fb3d8054","trusted":true,"execution":{"iopub.status.busy":"2025-06-29T14:14:42.415429Z","iopub.execute_input":"2025-06-29T14:14:42.415710Z","iopub.status.idle":"2025-06-29T14:15:19.489832Z","shell.execute_reply.started":"2025-06-29T14:14:42.415686Z","shell.execute_reply":"2025-06-29T14:15:19.489131Z"}},"outputs":[{"name":"stdout","text":"Collecting mediapipe\n  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\nRequirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\nRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\nRequirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\nRequirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.7.2)\nRequirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\nRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\nCollecting protobuf<5,>=4.25.3 (from mediapipe)\n  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\nCollecting sounddevice>=0.4.4 (from mediapipe)\n  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2->mediapipe) (2.4.1)\nRequirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\nRequirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\nRequirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\nRequirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2->mediapipe) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2->mediapipe) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2->mediapipe) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2->mediapipe) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2->mediapipe) (2024.2.0)\nDownloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\nInstalling collected packages: protobuf, sounddevice, mediapipe\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 4.25.8 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed mediapipe-0.10.21 protobuf-4.25.8 sounddevice-0.5.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport mediapipe as mp\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"_uuid":"a9db09a0-c5ea-4445-9e0b-f9583fcbdb1c","_cell_guid":"32b91e31-daac-44ab-98e4-efae2f10d95e","trusted":true,"execution":{"iopub.status.busy":"2025-06-29T14:15:19.491379Z","iopub.execute_input":"2025-06-29T14:15:19.491658Z","iopub.status.idle":"2025-06-29T14:15:46.180464Z","shell.execute_reply.started":"2025-06-29T14:15:19.491631Z","shell.execute_reply":"2025-06-29T14:15:46.179716Z"}},"outputs":[{"name":"stderr","text":"2025-06-29 14:15:23.707842: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751206524.175211      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751206524.289399      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"KAGGLE_DATA_PATH = '/kaggle/input/include/Adjectives_1of8'\n\nWORKING_DIR = '/kaggle/working/'\nCROPPED_FRAMES_DIR = os.path.join(WORKING_DIR, 'yolo_cropped_frames')\nLANDMARKS_DIR = os.path.join(WORKING_DIR, 'extracted_landmarks')\n\nos.makedirs(CROPPED_FRAMES_DIR, exist_ok=True)\nos.makedirs(LANDMARKS_DIR, exist_ok=True)\n\nprint(f\"Kaggle Data Path: {KAGGLE_DATA_PATH}\")\nprint(f\"Working Directory: {WORKING_DIR}\")","metadata":{"_uuid":"95aa8559-a6c9-4b9b-a29b-f66aefd30e27","_cell_guid":"cc803e3a-2988-48cf-aa7c-2be820eb802b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-29T14:15:46.181284Z","iopub.execute_input":"2025-06-29T14:15:46.182277Z","iopub.status.idle":"2025-06-29T14:15:46.187132Z","shell.execute_reply.started":"2025-06-29T14:15:46.182246Z","shell.execute_reply":"2025-06-29T14:15:46.186494Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Kaggle Data Path: /kaggle/input/include/Adjectives_1of8\nWorking Directory: /kaggle/working/\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"#### Extracting Landmarks","metadata":{}},{"cell_type":"code","source":"file_paths = []\n\nfor root, dirs, files in os.walk(KAGGLE_DATA_PATH):\n    for file in files:\n        if file.endswith('.MOV'):\n            file_path = os.path.join(root, file)\n            path_components = file_path.split('/')    \n            for component in reversed(path_components):\n                if '. ' in component:\n                 word = component.split('. ')[1]\n            file_paths.append([word.lower(), file_path])\n\nfile_paths = np.array(file_paths)\nfile_paths.shape","metadata":{"_uuid":"8d0c92c4-8145-4de9-8576-47b995549f82","_cell_guid":"e49e5a53-c68f-41f5-8e62-38adc4549901","trusted":true,"execution":{"iopub.status.busy":"2025-06-29T14:15:55.365864Z","iopub.execute_input":"2025-06-29T14:15:55.366109Z","iopub.status.idle":"2025-06-29T14:15:55.390410Z","shell.execute_reply.started":"2025-06-29T14:15:55.366092Z","shell.execute_reply":"2025-06-29T14:15:55.389788Z"},"jupyter":{"source_hidden":true}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(104, 2)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"def extract_landmarks(frame, holistic_model, frame_number=None):\n    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    results = holistic_model.process(rgb_frame)\n\n    expected_pose_size = 33 * 4\n    expected_face_size = 468 * 3\n    expected_hand_size = 21 * 3\n\n    def get_landmarks_data(landmarks_obj, expected_size, include_visibility=False):\n        if landmarks_obj:\n            if include_visibility:\n                data = np.array([[lmk.x, lmk.y, lmk.z, lmk.visibility] for lmk in landmarks_obj.landmark]).flatten()\n            else:\n                data = np.array([[lmk.x, lmk.y, lmk.z] for lmk in landmarks_obj.landmark]).flatten()\n            return data\n        return np.zeros(expected_size)\n\n    pose_data = get_landmarks_data(results.pose_landmarks, expected_pose_size, include_visibility=True)\n    face_data = get_landmarks_data(results.face_landmarks, expected_face_size)\n    left_hand_data = get_landmarks_data(results.left_hand_landmarks, expected_hand_size)\n    right_hand_data = get_landmarks_data(results.right_hand_landmarks, expected_hand_size)\n\n    full_landmark_vector = np.concatenate([pose_data, face_data, left_hand_data, right_hand_data])\n    \n    return full_landmark_vector","metadata":{"_uuid":"c0711c62-e510-4c01-aebf-e86d1e9c561b","_cell_guid":"2ff12fe4-68c6-4fc8-a106-e2d5ac8f335b","trusted":true,"execution":{"iopub.status.busy":"2025-06-29T14:08:23.139758Z","iopub.execute_input":"2025-06-29T14:08:23.140190Z","iopub.status.idle":"2025-06-29T14:08:23.146019Z","shell.execute_reply.started":"2025-06-29T14:08:23.140171Z","shell.execute_reply":"2025-06-29T14:08:23.145303Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"mp_holistic = mp.solutions.holistic\n\ndef process_videos(file_paths):\n    holistic_model = mp_holistic.Holistic(\n        static_image_mode=False, \n        model_complexity=2,\n        min_detection_confidence=0.5, \n        min_tracking_confidence=0.5\n    )\n\n    video_landmarks = []\n    labels = []\n\n    SEQUENCE_LENGTH = 60\n    \n    for i, (word, file_path) in enumerate(file_paths):\n        print(f\"Processing video {i+1}/{len(file_paths)}: {file_path} for landmarks (word: {word})\")\n        \n        cap = cv2.VideoCapture(file_path)\n        if not cap.isOpened():\n            print(f\"Error: Could not open video file {file_path}. Skipping.\")\n            continue\n\n        current_video_landmarks = []\n        frame_count = 0  \n\n        while True:\n            ret, frame = cap.read()\n            if not ret:\n                break\n\n            landmarks_frame = extract_landmarks(frame, holistic_model, frame_count)\n            if landmarks_frame is not None:\n                current_video_landmarks.append(landmarks_frame)\n\n            frame_count += 1\n\n        cap.release()\n\n        if not current_video_landmarks:\n            print(f\"No valid frames or landmarks extracted from {file_path}. Skipping video.\")\n            continue\n\n        video_sequence_array = np.array(current_video_landmarks)\n\n        if video_sequence_array.shape[0] < SEQUENCE_LENGTH:\n            padding_needed = SEQUENCE_LENGTH - video_sequence_array.shape[0]\n            padded_sequence = np.pad(video_sequence_array, \n                                     ((0, padding_needed), (0, 0)), \n                                     mode='constant', constant_values=0)\n            video_landmarks.append(padded_sequence)\n        elif video_sequence_array.shape[0] > SEQUENCE_LENGTH:\n            truncated_sequence = video_sequence_array[:SEQUENCE_LENGTH, :]\n            video_landmarks.append(truncated_sequence)\n        else:\n            video_landmarks.append(video_sequence_array)\n        \n        labels.append(word)\n                    \n    video_landmarks = np.array(video_landmarks)\n    labels = np.array(labels)\n\n    np.save(os.path.join(LANDMARKS_DIR, 'pose_landmarks_landmarks.npy'), video_landmarks)\n    np.save(os.path.join(LANDMARKS_DIR, 'pose_landmarks_labels.npy'), labels)\n\n    label_encoder = LabelEncoder()\n    y_encoded = label_encoder.fit_transform(labels)\n\n    print(f\"\\nSaved {video_landmarks.shape[0]} sequences and labels to {LANDMARKS_DIR}\")\n    print(f\"Shape of extracted sequences (X): {video_landmarks.shape}\")\n    print(f\"Shape of encoded labels (y): {y_encoded.shape}\")\n\n    holistic_model.close()","metadata":{"_uuid":"a0675d10-6936-4607-af89-ea2513f439c1","_cell_guid":"b4f09914-8f32-408c-91bf-d1b2d4eea48e","trusted":true,"execution":{"iopub.status.busy":"2025-06-29T14:08:23.146850Z","iopub.execute_input":"2025-06-29T14:08:23.147091Z","iopub.status.idle":"2025-06-29T14:08:23.174513Z","shell.execute_reply.started":"2025-06-29T14:08:23.147071Z","shell.execute_reply":"2025-06-29T14:08:23.173989Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"process_videos(file_paths)","metadata":{"_uuid":"19d34f22-b7bc-4b50-b0f5-b2960c8e1079","_cell_guid":"1b89fc23-30c8-4260-8902-56aaa7bd5288","trusted":true,"collapsed":true,"execution":{"iopub.status.busy":"2025-06-29T13:41:56.686535Z","iopub.execute_input":"2025-06-29T13:41:56.686812Z","iopub.status.idle":"2025-06-29T13:52:23.287821Z","shell.execute_reply.started":"2025-06-29T13:41:56.686793Z","shell.execute_reply":"2025-06-29T13:52:23.287092Z"},"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Processing video 1/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_9290.MOV for landmarks (word: loud)\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1751204516.881070     120 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751204517.068334     120 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751204517.072744     122 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751204517.075403     119 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751204517.078152     121 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751204517.108377     119 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751204517.110626     121 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751204517.123995     122 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","output_type":"stream"},{"name":"stdout","text":"Processing video 2/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_5258.MOV for landmarks (word: loud)\nProcessing video 3/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_9536.MOV for landmarks (word: loud)\nProcessing video 4/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_5257.MOV for landmarks (word: loud)\nProcessing video 5/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_5177.MOV for landmarks (word: loud)\nProcessing video 6/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_5259.MOV for landmarks (word: loud)\nProcessing video 7/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_9535.MOV for landmarks (word: loud)\nProcessing video 8/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_9449.MOV for landmarks (word: loud)\nProcessing video 9/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_9450.MOV for landmarks (word: loud)\nProcessing video 10/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_5179.MOV for landmarks (word: loud)\nProcessing video 11/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_9369.MOV for landmarks (word: loud)\nProcessing video 12/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_5335.MOV for landmarks (word: loud)\nProcessing video 13/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_9448.MOV for landmarks (word: loud)\nProcessing video 14/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_5178.MOV for landmarks (word: loud)\nProcessing video 15/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_9368.MOV for landmarks (word: loud)\nProcessing video 16/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_9291.MOV for landmarks (word: loud)\nProcessing video 17/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_5337.MOV for landmarks (word: loud)\nProcessing video 18/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_5336.MOV for landmarks (word: loud)\nProcessing video 19/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_9289.MOV for landmarks (word: loud)\nProcessing video 20/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_9370.MOV for landmarks (word: loud)\nProcessing video 21/104: /kaggle/input/include/Adjectives_1of8/Adjectives/1. loud/MVI_9534.MOV for landmarks (word: loud)\nProcessing video 22/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_9541.MOV for landmarks (word: happy)\nProcessing video 23/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_9456.MOV for landmarks (word: happy)\nProcessing video 24/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_5342.MOV for landmarks (word: happy)\nProcessing video 25/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_5184.MOV for landmarks (word: happy)\nProcessing video 26/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_9454.MOV for landmarks (word: happy)\nProcessing video 27/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_5185.MOV for landmarks (word: happy)\nProcessing video 28/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_9542.MOV for landmarks (word: happy)\nProcessing video 29/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_5265.MOV for landmarks (word: happy)\nProcessing video 30/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_9455.MOV for landmarks (word: happy)\nProcessing video 31/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_9297.MOV for landmarks (word: happy)\nProcessing video 32/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_9375.MOV for landmarks (word: happy)\nProcessing video 33/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_9296.MOV for landmarks (word: happy)\nProcessing video 34/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_9374.MOV for landmarks (word: happy)\nProcessing video 35/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_9295.MOV for landmarks (word: happy)\nProcessing video 36/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_9376.MOV for landmarks (word: happy)\nProcessing video 37/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_5263.MOV for landmarks (word: happy)\nProcessing video 38/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_5183.MOV for landmarks (word: happy)\nProcessing video 39/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_9540.MOV for landmarks (word: happy)\nProcessing video 40/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_5341.MOV for landmarks (word: happy)\nProcessing video 41/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_5343.MOV for landmarks (word: happy)\nProcessing video 42/104: /kaggle/input/include/Adjectives_1of8/Adjectives/3. happy/MVI_5264.MOV for landmarks (word: happy)\nProcessing video 43/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_9292.MOV for landmarks (word: quiet)\nProcessing video 44/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_5181.MOV for landmarks (word: quiet)\nProcessing video 45/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_9539.MOV for landmarks (word: quiet)\nProcessing video 46/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_9371.MOV for landmarks (word: quiet)\nProcessing video 47/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_5260.MOV for landmarks (word: quiet)\nProcessing video 48/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_9538.MOV for landmarks (word: quiet)\nProcessing video 49/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_9537.MOV for landmarks (word: quiet)\nProcessing video 50/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_5182.MOV for landmarks (word: quiet)\nProcessing video 51/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_5340.MOV for landmarks (word: quiet)\nProcessing video 52/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_9452.MOV for landmarks (word: quiet)\nProcessing video 53/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_5339.MOV for landmarks (word: quiet)\nProcessing video 54/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_5261.MOV for landmarks (word: quiet)\nProcessing video 55/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_9451.MOV for landmarks (word: quiet)\nProcessing video 56/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_9293.MOV for landmarks (word: quiet)\nProcessing video 57/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_9294.MOV for landmarks (word: quiet)\nProcessing video 58/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_9373.MOV for landmarks (word: quiet)\nProcessing video 59/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_5338.MOV for landmarks (word: quiet)\nProcessing video 60/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_5180.MOV for landmarks (word: quiet)\nProcessing video 61/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_5262.MOV for landmarks (word: quiet)\nProcessing video 62/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_9372.MOV for landmarks (word: quiet)\nProcessing video 63/104: /kaggle/input/include/Adjectives_1of8/Adjectives/2. quiet/MVI_9453.MOV for landmarks (word: quiet)\nProcessing video 64/104: /kaggle/input/include/Adjectives_1of8/Adjectives/7. Deaf/MVI_9848.MOV for landmarks (word: deaf)\nProcessing video 65/104: /kaggle/input/include/Adjectives_1of8/Adjectives/7. Deaf/MVI_9851.MOV for landmarks (word: deaf)\nProcessing video 66/104: /kaggle/input/include/Adjectives_1of8/Adjectives/7. Deaf/MVI_9583.MOV for landmarks (word: deaf)\nProcessing video 67/104: /kaggle/input/include/Adjectives_1of8/Adjectives/7. Deaf/MVI_9849.MOV for landmarks (word: deaf)\nProcessing video 68/104: /kaggle/input/include/Adjectives_1of8/Adjectives/7. Deaf/MVI_9582.MOV for landmarks (word: deaf)\nProcessing video 69/104: /kaggle/input/include/Adjectives_1of8/Adjectives/7. Deaf/MVI_9581.MOV for landmarks (word: deaf)\nProcessing video 70/104: /kaggle/input/include/Adjectives_1of8/Adjectives/7. Deaf/MVI_9580.MOV for landmarks (word: deaf)\nProcessing video 71/104: /kaggle/input/include/Adjectives_1of8/Adjectives/7. Deaf/MVI_9850.MOV for landmarks (word: deaf)\nProcessing video 72/104: /kaggle/input/include/Adjectives_1of8/Adjectives/8. Blind/MVI_9586.MOV for landmarks (word: blind)\nProcessing video 73/104: /kaggle/input/include/Adjectives_1of8/Adjectives/8. Blind/MVI_9585.MOV for landmarks (word: blind)\nProcessing video 74/104: /kaggle/input/include/Adjectives_1of8/Adjectives/8. Blind/MVI_9854.MOV for landmarks (word: blind)\nProcessing video 75/104: /kaggle/input/include/Adjectives_1of8/Adjectives/8. Blind/MVI_9587.MOV for landmarks (word: blind)\nProcessing video 76/104: /kaggle/input/include/Adjectives_1of8/Adjectives/8. Blind/MVI_9584.MOV for landmarks (word: blind)\nProcessing video 77/104: /kaggle/input/include/Adjectives_1of8/Adjectives/8. Blind/MVI_9855.MOV for landmarks (word: blind)\nProcessing video 78/104: /kaggle/input/include/Adjectives_1of8/Adjectives/8. Blind/MVI_9852.MOV for landmarks (word: blind)\nProcessing video 79/104: /kaggle/input/include/Adjectives_1of8/Adjectives/8. Blind/MVI_9853.MOV for landmarks (word: blind)\nProcessing video 80/104: /kaggle/input/include/Adjectives_1of8/Adjectives/5. Beautiful/MVI_9570.MOV for landmarks (word: beautiful)\nProcessing video 81/104: /kaggle/input/include/Adjectives_1of8/Adjectives/5. Beautiful/MVI_9723.MOV for landmarks (word: beautiful)\nProcessing video 82/104: /kaggle/input/include/Adjectives_1of8/Adjectives/5. Beautiful/MVI_9569.MOV for landmarks (word: beautiful)\nProcessing video 83/104: /kaggle/input/include/Adjectives_1of8/Adjectives/5. Beautiful/MVI_9724.MOV for landmarks (word: beautiful)\nProcessing video 84/104: /kaggle/input/include/Adjectives_1of8/Adjectives/5. Beautiful/MVI_9571.MOV for landmarks (word: beautiful)\nProcessing video 85/104: /kaggle/input/include/Adjectives_1of8/Adjectives/5. Beautiful/MVI_9726.MOV for landmarks (word: beautiful)\nProcessing video 86/104: /kaggle/input/include/Adjectives_1of8/Adjectives/5. Beautiful/MVI_9572.MOV for landmarks (word: beautiful)\nProcessing video 87/104: /kaggle/input/include/Adjectives_1of8/Adjectives/5. Beautiful/MVI_9725.MOV for landmarks (word: beautiful)\nProcessing video 88/104: /kaggle/input/include/Adjectives_1of8/Adjectives/5. Beautiful/Extra/MVI_9573.MOV for landmarks (word: beautiful)\nProcessing video 89/104: /kaggle/input/include/Adjectives_1of8/Adjectives/4. sad/MVI_9565.MOV for landmarks (word: sad)\nProcessing video 90/104: /kaggle/input/include/Adjectives_1of8/Adjectives/4. sad/MVI_9568.MOV for landmarks (word: sad)\nProcessing video 91/104: /kaggle/input/include/Adjectives_1of8/Adjectives/4. sad/MVI_9720.MOV for landmarks (word: sad)\nProcessing video 92/104: /kaggle/input/include/Adjectives_1of8/Adjectives/4. sad/MVI_9719.MOV for landmarks (word: sad)\nProcessing video 93/104: /kaggle/input/include/Adjectives_1of8/Adjectives/4. sad/MVI_9722.MOV for landmarks (word: sad)\nProcessing video 94/104: /kaggle/input/include/Adjectives_1of8/Adjectives/4. sad/MVI_9566.MOV for landmarks (word: sad)\nProcessing video 95/104: /kaggle/input/include/Adjectives_1of8/Adjectives/4. sad/MVI_9721.MOV for landmarks (word: sad)\nProcessing video 96/104: /kaggle/input/include/Adjectives_1of8/Adjectives/4. sad/MVI_9567.MOV for landmarks (word: sad)\nProcessing video 97/104: /kaggle/input/include/Adjectives_1of8/Adjectives/6. Ugly/MVI_9579.MOV for landmarks (word: ugly)\nProcessing video 98/104: /kaggle/input/include/Adjectives_1of8/Adjectives/6. Ugly/MVI_9578.MOV for landmarks (word: ugly)\nProcessing video 99/104: /kaggle/input/include/Adjectives_1of8/Adjectives/6. Ugly/MVI_9845.MOV for landmarks (word: ugly)\nProcessing video 100/104: /kaggle/input/include/Adjectives_1of8/Adjectives/6. Ugly/MVI_9846.MOV for landmarks (word: ugly)\nProcessing video 101/104: /kaggle/input/include/Adjectives_1of8/Adjectives/6. Ugly/MVI_9844.MOV for landmarks (word: ugly)\nProcessing video 102/104: /kaggle/input/include/Adjectives_1of8/Adjectives/6. Ugly/MVI_9576.MOV for landmarks (word: ugly)\nProcessing video 103/104: /kaggle/input/include/Adjectives_1of8/Adjectives/6. Ugly/MVI_9847.MOV for landmarks (word: ugly)\nProcessing video 104/104: /kaggle/input/include/Adjectives_1of8/Adjectives/6. Ugly/MVI_9577.MOV for landmarks (word: ugly)\n\nSaved 104 sequences and labels to /kaggle/working/extracted_landmarks\nShape of extracted sequences (X): (104, 60, 1662)\nShape of encoded labels (y): (104,)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"X = np.load(os.path.join(LANDMARKS_DIR, 'pose_landmarks_landmarks.npy'))\ny = np.load(os.path.join(LANDMARKS_DIR, 'pose_landmarks_labels.npy'))","metadata":{"_uuid":"5751625b-3481-4d52-9576-b93473828c83","_cell_guid":"b44f1fb6-0adf-43b8-a1e1-fad2c21fa07e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-29T13:53:32.578605Z","iopub.execute_input":"2025-06-29T13:53:32.578927Z","iopub.status.idle":"2025-06-29T13:53:32.610384Z","shell.execute_reply.started":"2025-06-29T13:53:32.578867Z","shell.execute_reply":"2025-06-29T13:53:32.609803Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"X = np.load(\"/kaggle/input/npy-files-input/pose_landmarks_landmarks.npy\")\ny = np.load(\"/kaggle/input/npy-files-input/pose_landmarks_labels.npy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T14:15:46.301390Z","iopub.execute_input":"2025-06-29T14:15:46.301601Z","iopub.status.idle":"2025-06-29T14:15:46.911974Z","shell.execute_reply.started":"2025-06-29T14:15:46.301586Z","shell.execute_reply":"2025-06-29T14:15:46.911408Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"X[0]","metadata":{"_uuid":"0abcdf24-2d49-4ea8-a5d1-78599457e778","_cell_guid":"c33176cc-a5ae-4f98-80b0-bb07b8808cdc","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-29T14:16:05.573041Z","iopub.execute_input":"2025-06-29T14:16:05.573307Z","iopub.status.idle":"2025-06-29T14:16:05.579929Z","shell.execute_reply.started":"2025-06-29T14:16:05.573288Z","shell.execute_reply":"2025-06-29T14:16:05.579133Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"array([[ 0.48630583,  0.35479909, -0.52718693, ...,  0.41376522,\n         1.00503421,  0.0080107 ],\n       [ 0.48621017,  0.35488755, -0.52777106, ...,  0.40040633,\n         0.99176592,  0.01896957],\n       [ 0.48612928,  0.35488304, -0.53528559, ...,  0.41364419,\n         1.00260413,  0.00648379],\n       ...,\n       [ 0.48132306,  0.35261399, -0.5267334 , ...,  0.38702124,\n         0.97029626,  0.01263577],\n       [ 0.48132119,  0.35275587, -0.54307491, ...,  0.38727611,\n         0.9713316 ,  0.01174397],\n       [ 0.4813233 ,  0.35286936, -0.52748704, ...,  0.38933939,\n         0.97365218,  0.01501061]])"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"X.shape","metadata":{"_uuid":"980ba270-eb85-42e9-bd21-c19f8bdb71d6","_cell_guid":"016e3f53-96a8-402a-b22e-5786eac436f9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-29T14:15:46.919727Z","iopub.execute_input":"2025-06-29T14:15:46.920085Z","iopub.status.idle":"2025-06-29T14:15:46.936428Z","shell.execute_reply.started":"2025-06-29T14:15:46.920056Z","shell.execute_reply":"2025-06-29T14:15:46.935798Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(104, 60, 1662)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"y.shape","metadata":{"_uuid":"02d2c9df-f10d-4191-9adc-44435a57c4f9","_cell_guid":"b0287b5d-8a51-4bd1-80f2-c6c94d0440e5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-29T14:15:46.937130Z","iopub.execute_input":"2025-06-29T14:15:46.937406Z","iopub.status.idle":"2025-06-29T14:15:46.953445Z","shell.execute_reply.started":"2025-06-29T14:15:46.937358Z","shell.execute_reply":"2025-06-29T14:15:46.952772Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(104,)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\nfrom tensorflow.keras.layers import Conv1D, TimeDistributed, Flatten, MaxPooling1D\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Dropout\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# Initialize label encoder\nlabel_encoder = LabelEncoder()\n\n# Fit label encoder on the labels and transform them\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\n# Now, y_train_encoded and y_test_encoded should be arrays of integers\ncategories = label_encoder.classes_\n\n# Print the categories\nprint(\"Encoded Categories:\")\nprint(categories)\n\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dropout, Dense, TimeDistributed\nfrom tensorflow.keras.layers import Reshape\nfrom keras.optimizers import Adam\nimport tensorflow as tf\n\n# Assuming your y_train_encoded and y_test_encoded are now integer encoded\nnum_classes = len(np.unique(y_train_encoded))\n\nmodel = Sequential()\n# model.add(TimeDistributed(Reshape((x_train.shape[2], 1)), input_shape=(x_train.shape[1], x_train.shape[2])))\n# model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n# model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n# model.add(TimeDistributed(Flatten()))\nmodel.add(LSTM(128, return_sequences=True), input_shape=(x_train.shape[1], x_train.shape[2]))\nmodel.add(Dropout(0.5)) \nmodel.add(LSTM(64)) \nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.3)) \nmodel.add(Dense(num_classes, activation='softmax'))\n\noptimizer = Adam(learning_rate=0.0001)\nmodel.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(x_train, y_train_encoded, validation_data=(x_test, y_test_encoded), epochs=100, batch_size=8)\n\nloss, accuracy = model.evaluate(x_test, y_test_encoded)\nprint('Test Loss:', loss)\nprint('Test Accuracy:', accuracy)","metadata":{"_uuid":"d822e4f0-822d-4ba4-b7b8-6b68b1e4c965","_cell_guid":"23d7d535-1866-4ee4-957a-0fa042b3489f","trusted":true,"execution":{"iopub.status.busy":"2025-06-29T14:40:10.131784Z","iopub.execute_input":"2025-06-29T14:40:10.132513Z","iopub.status.idle":"2025-06-29T14:41:20.714226Z","shell.execute_reply.started":"2025-06-29T14:40:10.132488Z","shell.execute_reply":"2025-06-29T14:41:20.713028Z"}},"outputs":[{"name":"stdout","text":"Encoded Categories:\n['beautiful' 'blind' 'deaf' 'happy' 'loud' 'quiet' 'sad' 'ugly']\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2487387059.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL ResourceExhaustedError REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/errors_impl.py(377): __init__\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py(53): quick_execute\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py(1683): call_function\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py(251): call_flat\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py(216): call_preflattened\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py(1322): _call_flat\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(919): _call\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(833): __call__\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py(219): function\n  /usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py(371): fit\n  /usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py(117): error_handler\n  /tmp/ipykernel_35/2487387059.py(51): <cell line: 0>\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3553): run_code\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3473): run_ast_nodes\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3257): run_cell_async\n  /usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py(78): _pseudo_sync_runner\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3030): _run_cell\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(2975): run_cell\n  /usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py(528): run_cell\n  /usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py(383): do_execute\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(730): execute_request\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(406): dispatch_shell\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(499): process_one\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(510): dispatch_queue\n  /usr/lib/python3.11/asyncio/events.py(84): _run\n  /usr/lib/python3.11/asyncio/base_events.py(1936): _run_once\n  /usr/lib/python3.11/asyncio/base_events.py(608): run_forever\n  /usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py(205): start\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py(712): start\n  /usr/local/lib/python3.11/dist-packages/traitlets/config/application.py(992): launch_instance\n  /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py(37): <module>\n  <frozen runpy>(88): _run_code\n  <frozen runpy>(198): _run_module_as_main\n"],"ename":"RuntimeError","evalue":"pybind11::error_already_set: MISMATCH of original and normalized active exception types: ORIGINAL ResourceExhaustedError REPLACED BY KeyboardInterrupt: <EMPTY MESSAGE>\n\nAt:\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/errors_impl.py(377): __init__\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py(53): quick_execute\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py(1683): call_function\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py(251): call_flat\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py(216): call_preflattened\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py(1322): _call_flat\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(919): _call\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py(833): __call__\n  /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py(150): error_handler\n  /usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py(219): function\n  /usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py(371): fit\n  /usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py(117): error_handler\n  /tmp/ipykernel_35/2487387059.py(51): <cell line: 0>\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3553): run_code\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3473): run_ast_nodes\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3257): run_cell_async\n  /usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py(78): _pseudo_sync_runner\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(3030): _run_cell\n  /usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py(2975): run_cell\n  /usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py(528): run_cell\n  /usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py(383): do_execute\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(730): execute_request\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(406): dispatch_shell\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(499): process_one\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py(510): dispatch_queue\n  /usr/lib/python3.11/asyncio/events.py(84): _run\n  /usr/lib/python3.11/asyncio/base_events.py(1936): _run_once\n  /usr/lib/python3.11/asyncio/base_events.py(608): run_forever\n  /usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py(205): start\n  /usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py(712): start\n  /usr/local/lib/python3.11/dist-packages/traitlets/config/application.py(992): launch_instance\n  /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py(37): <module>\n  <frozen runpy>(88): _run_code\n  <frozen runpy>(198): _run_module_as_main\n","output_type":"error"}],"execution_count":25},{"cell_type":"code","source":"model.save(\"demo_lstm_85.h5\")","metadata":{"_uuid":"ca67536a-8555-4cb6-989c-1550db50082e","_cell_guid":"9fede723-a8fa-4891-8148-01b925c4ff34","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-29T11:29:24.151928Z","iopub.execute_input":"2025-06-29T11:29:24.152488Z","iopub.status.idle":"2025-06-29T11:29:24.200635Z","shell.execute_reply.started":"2025-06-29T11:29:24.152465Z","shell.execute_reply":"2025-06-29T11:29:24.200123Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}